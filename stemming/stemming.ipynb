{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer \n",
    "import os # for manipulating directory paths\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use a nltk library for the stemming\n",
    "\n",
    "PorterStemmer and LancasterStemmer are two classes of two stemmers\n",
    "\n",
    "\n",
    "nltk.download() is needed in order to download some model that we may need later\n",
    "\n",
    "I've installed the punkt model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "porter stemming algorithm works faster and simpler\n",
    "\n",
    "it just removes suffixes\n",
    "\n",
    "\n",
    "\n",
    "lancaster stemming algorithm uses 120 rules and it iterates until no rule is applicable\n",
    "\n",
    "I decides to use the first one one because it's faster and our problem is pretty simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(word):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    return porter.stem(word)\n",
    "\n",
    "stem(\"Maths\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.array([])\n",
    "\n",
    "with open(os.path.os.path.abspath('../data/train.csv'), 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "\n",
    "    for line in csv_reader:\n",
    "        tweets = np.append(tweets, line[3])\n",
    "    tweets = np.delete(tweets, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Our', 'Deeds', 'are', ..., 'ABC', 'News',\n",
       "       'http://t.co/YmY4rSkQ3d'], dtype='<U62')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = np.array([])\n",
    "for text in tweets:\n",
    "    words = np.append(words, text.split())\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['our', 'deed', 'are', ..., 'abc', 'new', 'http://t.co/ymy4rskq3d'],\n",
       "      dtype='<U62')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(words.size):\n",
    "    words[i] = stem(words[i])\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_array(array):\n",
    "    words = np.array([])\n",
    "    for text in array:\n",
    "        words = np.append(words, text.split())\n",
    "    for i in range(words.size):\n",
    "        words[i] = stem(words[i])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_from_csv(csv_path, column):\n",
    "    tweets = np.array([])\n",
    "\n",
    "    with open(csv_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "\n",
    "        for line in csv_reader:\n",
    "            tweets = np.append(tweets, line[column])\n",
    "    tweets = np.delete(tweets, 0)\n",
    "\n",
    "    words = stem_array(tweets)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['our', 'deed', 'are', ..., 'abc', 'new', 'http://t.co/ymy4rskq3d'],\n",
       "      dtype='<U62')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_from_csv(os.path.abspath('../data/train.csv'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(csv_path, words):\n",
    "    with open(csv_path, 'w') as new_file:\n",
    "        csv_writer = csv.writer(new_file)\n",
    "\n",
    "        for i in words:\n",
    "            csv_writer.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(os.path.abspath('../data/words_stemmed.csv'), stem_from_csv(os.path.abspath('../data/train.csv'), 3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4f263c2694755e1f688dc706ecd0349fd812c6095f09f9c3954b10aae03b7c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('kaggle-NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
